}
View(sim_stats)
generate_resamples <- function(subset_data, sample_sizes = c(3, 5, 10, 15, 20, 25, 30), n_resamples = 1000) {
resampled_data <- lapply(sample_sizes, function(sample_size) {
replicate(n_resamples, mean(sample(subset_data$d18O, size = sample_size, replace = TRUE)))
})
return(data.frame(
sample_size = rep(sample_sizes, each = n_resamples),
resampled_d18O = unlist(resampled_data)
))
}
# Generate resamples for each eco_type
resampled_data <- grouped_data %>%
group_modify(~ generate_resamples(.x, n_resamples = 1000))
# Check the structure of the resampled_data
str(resampled_data)
# Function to calculate mean, standard error, and gather results
calculate_summary_stats <- function(resampled_data) {
eco_type <- unique(resampled_data$eco_type)[1]  # Assuming eco_type is the same for all rows
summary_stats <- resampled_data %>%
group_by(sample_size) %>%
summarise(
mean_d18Op = mean(resampled_d18O),
se_d18Op = sd(resampled_d18O) / sqrt(length(resampled_d18O)),
eco_type = eco_type
)
return(summary_stats)
}
# Apply the function to each group in resampled_data
sim_stats <- resampled_data %>%
group_split(eco_type) %>%
map_dfr(~ calculate_summary_stats(.x))
# Check the structure of the sim_stats
str(sim_stats)
# Plot se_d18Op against sample_size
#ggplot(sim_stats, aes(x = sample_size, y = se_d18Op)) +
geom_point() +
geom_line() +
labs(title = "Plot of se_d18Op against sample_size", x = "Sample Size", y = "se_d18Op")
# Calculate d18Omw estimates
#create d18Omw column
sim_stats$d18Omw <- NA
# calculate d18Omw
sim_stats <- sim_stats %>%
mutate(d18Omw = case_when(
eco_type == "Aquatic Turtle" & is.na(d18Omw) ~ 1.01 * mean_d18Op - 22.3,
eco_type == "Croc G" & is.na(d18Omw) ~ 0.82 * mean_d18Op - 19.93,
TRUE ~ d18Omw  # Keep existing values for other cases
))
# Check if only rows with eco_type = "Croc G" have non-missing d18Omw values
only_croc_g_rows <- sim_stats %>%
filter(eco_type == "Croc G") %>%
pull(d18Omw) %>%
complete.cases()
# Find unique eco_types with non-missing d18Omw values
eco_types_with_d18Omw <- sim_stats %>%
filter(!is.na(d18Omw)) %>%
distinct(eco_type)
# Print the results
if (all(only_croc_g_rows)) {
cat("All rows with eco_type = 'Croc G' have non-missing d18Omw values.\n")
} else {
cat("There are rows with eco_type = 'Croc G' that have missing d18Omw values.\n")
}
cat("Eco_types with non-missing d18Omw values:", unique(eco_types_with_d18Omw$eco_type), "\n")
# Subset data for "Croc G"
croc_g_data <- sim_stats %>%
filter(eco_type == "Croc G")
# Calculate simulated values
croc_g_data$sim_crocwater <- 0.82 * croc_g_data$mean_d18Op - 19.93
# Plot the distribution of sim_crocwater for "Croc G"
hist(croc_g_data$d18Omw, main = "Distribution of d18Omw estimates (simulated Croc G)", xlab = "sim_crocwater", col = "skyblue", border = "black")
# Subset data for "Fish"
gar_data <- sim_stats %>%
filter(eco_type == "Fish")
# Subset data for "Aquatic Turtle"
aquaturtle_data <- sim_stats %>%
filter(eco_type == "Aquatic Turtle")
# Set seed for reproducibility
set.seed(123)
# Create a data frame to store the results
croc_temps <- data.frame()
# Define the Croc_temp function
calculate_Croc_temp <- function(gar_d18Op_mean, croc_d18Omw, NIST120c_mean) {
return(118.7 - 4.22 * ((gar_d18Op_mean + (22.6 - NIST120c_mean)) - croc_d18Omw))
}
your_sample_sizes_vector <- unique(sim_stats$sample_size)
# Loop over each sample size
for (sample_size in your_sample_sizes_vector) {
# Generate combinations of data
combinations <- expand.grid(
gar_d18Op_mean = gar_data$mean_d18Op,
croc_d18Omw = croc_g_data$d18Omw
)
# Calculate Croc_temp for each combination
combinations$sample_size <- sample_size
combinations$Croc_temp <- calculate_Croc_temp(
combinations$gar_d18Op_mean,
combinations$croc_d18Omw,
NIST120c_mean
)
# Store the results in croc_temps
croc_temps <- rbind(croc_temps, combinations)
}
# Function to generate simulated dataset for a given eco_type
simulate_eco_type <- function(subset_data, n_simulations = 1000) {
mean_val <- mean(subset_data$d18O)
sd_val <- sd(subset_data$d18O)
simulated_values <- replicate(n_simulations, rnorm(1, mean_val, sd_val))
return(simulated_values)
}
# Generate simulated datasets for each eco_type
simulated_data <- grouped_data %>%
summarise(simulated_d18O = list(simulate_eco_type(cur_data(), n_simulations = 1000))) %>%
unnest(simulated_d18O)
# Check the structure of the simulated_data
str(simulated_data)
# Plot histograms of the simulated data to compare against the empirical data
ggplot(simulated_data, aes(x = simulated_d18O, fill = eco_type)) +
geom_histogram(binwidth = 0.2, position = "identity", alpha = 0.7) +
labs(title = "Simulated Histograms of d18O by eco_type", x = "Simulated d18O", y = "Frequency") +
scale_fill_manual(values = c("A" = "blue", "B" = "green")) +
facet_wrap(~eco_type, scales = "free") +
theme_minimal()
generate_resamples <- function(subset_data, sample_sizes = c(3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30), n_resamples = 1000) {
resampled_data <- lapply(sample_sizes, function(sample_size) {
replicate(n_resamples, mean(sample(subset_data$d18O, size = sample_size, replace = TRUE)))
})
return(data.frame(
sample_size = rep(sample_sizes, each = n_resamples),
resampled_d18O = unlist(resampled_data)
))
}
# Generate resamples for each eco_type
resampled_data <- grouped_data %>%
group_modify(~ generate_resamples(.x, n_resamples = 1000))
# Check the structure of the resampled_data
str(resampled_data)
# Function to calculate mean, standard error, and gather results
calculate_summary_stats <- function(resampled_data) {
eco_type <- unique(resampled_data$eco_type)[1]  # Assuming eco_type is the same for all rows
summary_stats <- resampled_data %>%
group_by(sample_size) %>%
summarise(
mean_d18Op = mean(resampled_d18O),
se_d18Op = sd(resampled_d18O) / sqrt(length(resampled_d18O)),
eco_type = eco_type
)
return(summary_stats)
}
# Apply the function to each group in resampled_data
sim_stats <- resampled_data %>%
group_split(eco_type) %>%
map_dfr(~ calculate_summary_stats(.x))
# Check the structure of the sim_stats
str(sim_stats)
# Plot se_d18Op against sample_size
#ggplot(sim_stats, aes(x = sample_size, y = se_d18Op)) +
geom_point() +
geom_line() +
labs(title = "Plot of se_d18Op against sample_size", x = "Sample Size", y = "se_d18Op")
# Calculate d18Omw estimates
#create d18Omw column
sim_stats$d18Omw <- NA
# calculate d18Omw
sim_stats <- sim_stats %>%
mutate(d18Omw = case_when(
eco_type == "Aquatic Turtle" & is.na(d18Omw) ~ 1.01 * mean_d18Op - 22.3,
eco_type == "Croc G" & is.na(d18Omw) ~ 0.82 * mean_d18Op - 19.93,
TRUE ~ d18Omw  # Keep existing values for other cases
))
# Check if only rows with eco_type = "Croc G" have non-missing d18Omw values
only_croc_g_rows <- sim_stats %>%
filter(eco_type == "Croc G") %>%
pull(d18Omw) %>%
complete.cases()
# Find unique eco_types with non-missing d18Omw values
eco_types_with_d18Omw <- sim_stats %>%
filter(!is.na(d18Omw)) %>%
distinct(eco_type)
# Print the results
if (all(only_croc_g_rows)) {
cat("All rows with eco_type = 'Croc G' have non-missing d18Omw values.\n")
} else {
cat("There are rows with eco_type = 'Croc G' that have missing d18Omw values.\n")
}
cat("Eco_types with non-missing d18Omw values:", unique(eco_types_with_d18Omw$eco_type), "\n")
# Subset data for "Croc G"
croc_g_data <- sim_stats %>%
filter(eco_type == "Croc G")
# Calculate simulated values
croc_g_data$sim_crocwater <- 0.82 * croc_g_data$mean_d18Op - 19.93
# Plot the distribution of sim_crocwater for "Croc G"
hist(croc_g_data$d18Omw, main = "Distribution of d18Omw estimates (simulated Croc G)", xlab = "sim_crocwater", col = "skyblue", border = "black")
# Subset data for "Fish"
gar_data <- sim_stats %>%
filter(eco_type == "Fish")
# Subset data for "Aquatic Turtle"
aquaturtle_data <- sim_stats %>%
filter(eco_type == "Aquatic Turtle")
# Set seed for reproducibility
set.seed(123)
# Create a data frame to store the results
croc_temps <- data.frame()
# Define the Croc_temp function
calculate_Croc_temp <- function(gar_d18Op_mean, croc_d18Omw, NIST120c_mean) {
return(118.7 - 4.22 * ((gar_d18Op_mean + (22.6 - NIST120c_mean)) - croc_d18Omw))
}
your_sample_sizes_vector <- unique(sim_stats$sample_size)
# Loop over each sample size
for (sample_size in your_sample_sizes_vector) {
# Generate combinations of data
combinations <- expand.grid(
gar_d18Op_mean = gar_data$mean_d18Op,
croc_d18Omw = croc_g_data$d18Omw
)
# Calculate Croc_temp for each combination
combinations$sample_size <- sample_size
combinations$Croc_temp <- calculate_Croc_temp(
combinations$gar_d18Op_mean,
combinations$croc_d18Omw,
NIST120c_mean
)
# Store the results in croc_temps
croc_temps <- rbind(croc_temps, combinations)
}
# Data
# GitHub raw URL for the CSV file
github_url <- "https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_BySpec.csv?token=GHSAT0AAAAAACK5C64YP2FUJUAVDV6RGKIUZLI4ANA"
# Read the CSV file into a data frame
V1075_BySpec <- read_csv(github_url)
View(V1075_BySpec)
V1075_BySpec <- V1075_BySpec[, -1]
write.csv(V1075_BySpec, "V1075_BySpec.csv")
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
V1075_BySpec <- V1075_BySpec[, -1]
write.csv(V1075_BySpec, "V1075_BySpec.csv")
View(V1075_BySpec)
write.csv(V1075_BySpec, "V1075_BySpec.csv")
write.csv(V1075_BySpec, "V1075_BySpec.csv")
V1075_BySpec <- V1075_BySpec[, -1]
# Packages, Functions
oxydelt <- expression("δ"^18 * "O‰ (VSMOW)")
# Define a list of packages to be installed and loaded
packages <- c("tidyverse", "knitr", "ggplot2", "plotrix")
# Check if each package is installed, and if not, install it
for (package in packages) {
if (!requireNamespace(package, quietly = TRUE)) {
install.packages(package, dependencies = TRUE)
}
}
# Load the required packages
library(knitr)
library(ggplot2)
library(tidyverse)
library(plotrix)
# Load compiled Cretaceous d180p dataset
setwd("/Users/allen/Documents/Data Analysis/Data")
lit_data <- read.csv("Cretaceous_d18Ocompile.csv")
# Load Cloverly V1075 data
# source("/Users/allen/Documents/Data Analysis/Code/V1075_d18O.R")
setwd("/Users/allen/Documents/Data Analysis/Data/")
# raw <- read.csv("vertd180/V1075_Run1_Results.csv")
# V1075 <- read.csv("V1075Results2.0.csv")
#V1075 <- read.csv("V1075_PhosphateSamples copy.csv")
V1075 <- read.csv("V1075_PhosphateData_8-18-23_copy.csv")
# eval for and remove outliers
# outliers identified in Croc A, Small Theropod
V1075 <- subset(V1075, V1075$d18O..VSMOW. < 22.47)
# 2 outliers removed
# remove dentine samples
V1075 <- subset(V1075, V1075$Tissue != "dentine")
# for each unique specimen in lit_data, calculate mean of that specimen
# use dplyr to summarize by group, assign to new dataframe
BySpec <- group_by(lit_data, specimen)
# compute mean and n by specimen
mean <- summarize(BySpec, d18O = mean(d18O_phosphate), n = n()) # remember that n = n() command produces column with sample size for each group
# SD <-aggregate(BySpec$d18O_phosphate, list(BySpec$specimen), FUN=sd)
SD <- summarize(BySpec, SD = sd(d18O_phosphate))
# clean and merge
# condense lit_data df to one row per unique specimen
lit_data_BySpec <- lit_data[!duplicated(lit_data$specimen), ]
# remove unwanted columns
lit_data_BySpec <- dplyr::select(lit_data_BySpec, c(-2, -7:-9))
# merge condensed lit_data with summarized data
lit_data_BySpec <- merge(lit_data_BySpec,mean,by="specimen")
lit_data_BySpec <- merge(lit_data_BySpec,SD,by="specimen")
# calculate SE and merge with lit_data_BySpec
lit_data_BySpec <- mutate(lit_data_BySpec, SE = (SD/sqrt(n)))
# Calculate sample size for each eco_type and site
sample_size_by_eco_site <- lit_data_BySpec %>%
group_by(eco_type, site) %>%
summarise(Sample_Size = n())
# Create the plot
ggplot(sample_size_by_eco_site, aes(x = site, y = Sample_Size, fill = eco_type)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Sample Size by Eco Type and Site",
x = "Site",
y = "Sample Size",
fill = "Eco Type") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability
# V1075
# for each unique specimen in V1075, calculate mean of that specimen
# use dplyr to summarize by group, assign to new dataframe
V1075_BySpec <- group_by(V1075, Specimen.ID)
# compute mean and n by specimen
V1075_mean <- summarize(V1075_BySpec, d18O = mean(d18O..VSMOW.), n = n()) # remember that n = n() command produces column with sample size for each group
SD <- summarize(V1075_BySpec, SD = sd(d18O..VSMOW.))
# clean and merge
# condense lit_data df to one row per unique specimen
V1075_BySpec <- V1075_BySpec[!duplicated(V1075_BySpec$Specimen.ID), ]
# remove unwanted columns
V1075_BySpec <- dplyr::select(V1075_BySpec, c(-1, -4:-8, -14:-26))
# merge condensed lit_data with summarized data
V1075_BySpec <- merge(V1075_BySpec,V1075_mean,by="Specimen.ID")
V1075_BySpec <- merge(V1075_BySpec,SD,by="Specimen.ID")
# calculate SE and merge with V1075_BySpec
V1075_BySpec <- mutate(V1075_BySpec, SE = (SD/sqrt(n)))
# rename columns consistent with lit_data dataset
names(V1075_BySpec)[names(V1075_BySpec) == "Eco"] <- "eco_type"
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
V1075_BySpec <- V1075_BySpec[]
write.csv(V1075_BySpec, "V1075_BySpec.csv")
View(V1075_BySpec)
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
write.csv(V1075_BySpec, "V1075_BySpec.csv")
write.csv(V1075_BySpec, "V1075_BySpec.csv", row.names = FALSE)
# Data
# GitHub raw URL for the CSV file
github_url <- "https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_BySpec.csv?token=GHSAT0AAAAAACK5C64YP2FUJUAVDV6RGKIUZLI4ANA"
# Read the CSV file into a data frame
V1075_BySpec <- read_csv(github_url)
# Data
# GitHub raw URL for the CSV file
github_url <- "https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_BySpec.csv?token=GHSAT0AAAAAACK5C64Z6LFW5YE2VQ7OCMAMZLI4MDQ"
# Read the CSV file into a data frame
V1075_BySpec <- read_csv(github_url)
str(V1075_BySpec)
# Data
# GitHub raw URL for the CSV file
github_url <- "https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_BySpec.csv"
# Read the CSV file into a data frame
V1075_BySpec <- read_csv(github_url)
str(V1075_BySpec)
# Packages
# Vector of package names
packages <- c("dplyr", "ggplot2", "readr", "magrittr", "tidyr", "purrr")
# Function to check and install packages
check_and_install_packages <- function(packages) {
# Check if each package is installed
missing_packages <- setdiff(packages, installed.packages()[,"Package"])
# Install missing packages
if (length(missing_packages) > 0) {
install.packages(missing_packages, dependencies = TRUE)
}
# Load all packages
loaded_packages <- sapply(packages, function(pkg) {
if (!requireNamespace(pkg, quietly = TRUE)) {
message(paste("Installing and loading", pkg))
install.packages(pkg, dependencies = TRUE)
}
library(pkg, character.only = TRUE)
})
# Return a logical vector indicating whether each package is successfully loaded
return(loaded_packages)
}
check_and_install_packages(packages)
# Data
# GitHub raw URL for the CSV file
github_url <- "https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_BySpec.csv"
# Read the CSV file into a data frame
V1075_BySpec <- read_csv(github_url)
str(V1075_BySpec)
knitr::opts_chunk$set(echo = TRUE)
# READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
# NEED NIST120C STD d18Op from Run 3!!!!!
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c_Run1%262.csv"
read_csv(standards_githubURL)
NIST120c <- read_csv(standards_githubURL)
hist(NIST120c$d.18O.16O)
View(NIST120c)
# READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
# NEED NIST120C STD d18Op from Run 3!!!!!
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c_Run1%262.csv"
# READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
# NEED NIST120C STD d18Op from Run 3!!!!!
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c_Run1%262.csv"
NIST120c <- read_csv(standards_githubURL)
hist(NIST120c$d18O.16O)
hist(NIST120c$d18O.16O)
setwd("/Users/allen/Documents/Data Analysis/Data/Geochem")
NIST120c <- read.csv("V1075_NIST120c_Run1&2.csv")
hist(NIST120c$d18O.16O)
# READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
# NEED NIST120C STD d18Op from Run 3!!!!!
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c_Run1%262.csv"
NIST120c <- read_csv(standards_githubURL)
NIST120c <- read_csv(standards_githubURL, spec())
NIST120c <- read_csv(standards_githubURL, spec(standards_githubURL))
spec()
spec(standards_githubURL)
hist(NIST120c$d18O.16O)
setwd("/Users/allen/Documents/Data Analysis/Data/Geochem")
NIST120c <- read.csv("V1075_NIST120c_Run1&2.csv")
hist(NIST120c$d18O.16O)
hist(NIST120c$d.18O.16O)
# identified a single outlier. Why just this one bust? Anyways, omit it.
NIST120c <- subset(NIST120c, NIST120c$d.18O.16O > 20)
hist(NIST120c$d.18O.16O)
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
write.csv(NIST120c, "V1075_NIST120c.csv", row.names = FALSE)
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
write.csv(NIST120c, "V1075_NIST120c.csv", row.names = FALSE)
# READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
# NEED NIST120C STD d18Op from Run 3!!!!!
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c_Run1%262.csv"
NIST120c <- read_csv(standards_githubURL)
hist(NIST120c$d.18O.16O)
hist(NIST120c$d18O.16O)
hist(NIST120c$d.18O.16O)
setwd("/Users/allen/Documents/Data Analysis/Data/Geochem")
NIST120c <- read.csv("V1075_NIST120c_Run1&2.csv")
hist(NIST120c$d.18O.16O)
# identified a single outlier. Why just this one bust? Anyways, omit it.
NIST120c <- subset(NIST120c, NIST120c$d.18O.16O > 20)
hist(NIST120c$d.18O.16O)
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
write.csv(NIST120c, "V1075_NIST120c.csv", row.names = FALSE)
write.csv(NIST120c, "V1075_NIST120c.csv", row.names = FALSE)
hist(NIST120c$d.18O.16O)
setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
write.csv(NIST120c, "V1075_NIST120c.csv", row.names = FALSE)
write.csv(NIST120c, "V1075_NIST120c.csv", row.names = FALSE)
hist(NIST120c$d18O.16O)
hist(NIST120c$d.18O.16O)
hist(NIST120c$d.18O.16O)
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c.csv"
NIST120c <- read_csv(standards_githubURL)
# READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
# NEED NIST120C STD d18Op from Run 3!!!!!
standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c.csv"
NIST120c <- read_csv(standards_githubURL)
# check for outliers
hist(NIST120c$d.18O.16O)
# gather mean
NIST120c_mean <- mean(NIST120c$d.18O.16O)
# Calculate d18Omw estimates
#create d18Omw column
sim_stats$d18Omw <- NA
# calculate d18Omw
sim_stats <- sim_stats %>%
mutate(d18Omw = case_when(
eco_type == "Aquatic Turtle" & is.na(d18Omw) ~ 1.01 * mean_d18Op - 22.3,
eco_type == "Croc G" & is.na(d18Omw) ~ 0.82 * mean_d18Op - 19.93,
TRUE ~ d18Omw  # Keep existing values for other cases
))
# Check if only rows with eco_type = "Croc G" have non-missing d18Omw values
only_croc_g_rows <- sim_stats %>%
filter(eco_type == "Croc G") %>%
pull(d18Omw) %>%
complete.cases()
# Find unique eco_types with non-missing d18Omw values
eco_types_with_d18Omw <- sim_stats %>%
filter(!is.na(d18Omw)) %>%
distinct(eco_type)
# Print the results
if (all(only_croc_g_rows)) {
cat("All rows with eco_type = 'Croc G' have non-missing d18Omw values.\n")
} else {
cat("There are rows with eco_type = 'Croc G' that have missing d18Omw values.\n")
}
cat("Eco_types with non-missing d18Omw values:", unique(eco_types_with_d18Omw$eco_type), "\n")
# Subset data for "Croc G"
croc_g_data <- sim_stats %>%
filter(eco_type == "Croc G")
# Calculate simulated values
croc_g_data$sim_crocwater <- 0.82 * croc_g_data$mean_d18Op - 19.93
# Plot the distribution of sim_crocwater for "Croc G"
hist(croc_g_data$d18Omw, main = "Distribution of d18Omw estimates (simulated Croc G)", xlab = "sim_crocwater", col = "skyblue", border = "black")
# Subset data for "Fish"
gar_data <- sim_stats %>%
filter(eco_type == "Fish")
# Subset data for "Aquatic Turtle"
aquaturtle_data <- sim_stats %>%
filter(eco_type == "Aquatic Turtle")
# Set seed for reproducibility
set.seed(123)
# Create a data frame to store the results
croc_temps <- data.frame()
# Define the Croc_temp function
calculate_Croc_temp <- function(gar_d18Op_mean, croc_d18Omw, NIST120c_mean) {
return(118.7 - 4.22 * ((gar_d18Op_mean + (22.6 - NIST120c_mean)) - croc_d18Omw))
}
your_sample_sizes_vector <- unique(sim_stats$sample_size)
# Loop over each sample size
for (sample_size in your_sample_sizes_vector) {
# Generate combinations of data
combinations <- expand.grid(
gar_d18Op_mean = gar_data$mean_d18Op,
croc_d18Omw = croc_g_data$d18Omw
)
# Calculate Croc_temp for each combination
combinations$sample_size <- sample_size
combinations$Croc_temp <- calculate_Croc_temp(
combinations$gar_d18Op_mean,
combinations$croc_d18Omw,
NIST120c_mean
)
# Store the results in croc_temps
croc_temps <- rbind(croc_temps, combinations)
}
