---
title: "Constructing Confidence Intervals around Proxy Parameters Derived from Vertebrate Isotopes"
author: "Matthew Allen"
date: "December 2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

#### I will flesh this out in the coming week. I'll introduce what I'm doing and why I'm doing it. I might suggest how this document/procedure might be used on future analyses.

Uncertainty of proxy estimates derived from vertebrate isotopes is influenced by sample size. It is important to test the sensitivity of a parameter to the number of specimens sampled for an analysis.

First, I will demonstrate how sample size might affect temperature estimates using simulated data based on an empirical dataset from a single assemblage in the Albian (mid-Cretaceous) of Montana. 

I will also run resampling simulations on the empirical data and construct confidence intervals on the temperature estimate.

## Demonstration 1: Monte Carlo on simulated data, dual-taxon temperature reconstruction
- Summary:
  1. Simulate large $\delta$^18^O~phosphate~ dataset with for each eco-type based on distribution of empirical data
  2. Generate random resamples of varying sample size from simulated data, gather summary statistics for each resample
  3. Compute $\delta$^18^O~ambient_water~ distribution
  4. Compute temperature distribution from $\delta$^18^O~ambient_water~ and $\delta$^18^O~phosphate_fish~
  5. Construct 95% confidence interval around mean of temperature distribution
  
## Demonstration 2: Monte Carlo on empirical data, dual-taxon temperature reconstruction
- Summary:
  1. Generate random resamples of varying sample from empirical data, gather summary statistics for each resample
  2. Compute $\delta$^18^O~ambient_water~ distribution
  3. Compute temperature distribution from $\delta$^18^O~ambient_water~ and $\delta$^18^O~phosphate_fish~
  4. Construct 95% confidence interval around mean of temperature distribution

#### Setup: Install/load packages, read data, clean and group data by eco-type 

Before we begin the procedure, let's load everything and set up our data. We will also check for normality of the data, and visualize the distribution of each eco-type

#### !!! Recompile NIST120c data, include run 3 !!!
#### !!! Output Shapiro-Wilk test results in table plot so it is visible in Rmarkdown !!!

```{r, results='hide', message=FALSE, warning=FALSE}

# Packages, Data, Objects -------------------------------------------------
  
  # Define required packages
    packages <- c("dplyr", "ggplot2", "readr", "magrittr", "tidyr", "purrr")

  # Create function to check, install, and load packages
    check_and_install_packages <- function(packages) {
      missing_packages <- setdiff(packages, installed.packages()[,"Package"])
      if (length(missing_packages) > 0) install.packages(missing_packages, dependencies = TRUE)
      sapply(packages, function(pkg) {
        if (!requireNamespace(pkg, quietly = TRUE)) {
          message(paste("Installing and loading", pkg))
          install.packages(pkg, dependencies = TRUE)
        }
        library(pkg, character.only = TRUE)
      })
    }

  # Run the package function
    check_and_install_packages(packages)

  # Data
    # Call d18Op data from GitHub, cleaned and averaged per specimen (V1075_BySpec.csv)
      samples_githubURL <- "https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_BySpec.csv"
      V1075_BySpec <- read_csv(samples_githubURL)
      
    # READ IN NIST120c STD d18Op VALUES FROM RUN 1 and RUN 2
      # NEED NIST120C STD d18Op from Run 3!!!!!
        standards_githubURL <-"https://raw.githubusercontent.com/mattgeo1990/1075_Vertebrate_d18Op/main/Data/V1075_NIST120c.csv"
        NIST120c <- read_csv(standards_githubURL)
        # gather mean
        NIST120c_mean <- mean(NIST120c$d.18O.16O)
  
  # Final Cleaning, Group by Eco-type
    # Omit Large Theropod and Sharks. Too few data and possible diagenetic influence
      V1075_MC <- subset(V1075_BySpec, eco_type != "Large Theropod" & eco_type != "Shark")
  
    # Group by eco_type
      grouped_data <- V1075_MC %>% group_by(eco_type)

  # Look at your data 
    # Plotting a panel of histograms by eco_type
      p <- ggplot(grouped_data, aes(x = d18O, fill = eco_type)) +
        geom_histogram(binwidth = 1, color = "black", alpha = 0.7) +
        labs(title = "Histogram of d18O by eco_type",
             x = "d18O",
             y = "Frequency") +
        theme_minimal() +
        facet_wrap(~eco_type, scales = "free")
      
    # Perform Shapiro-Wilk test for normality for each eco_type
      shapiro_tests <- by(grouped_data$d18O, grouped_data$eco_type, shapiro.test)
      
    # Display normality test results
      cat("\nNormality Tests:\n")
      print(shapiro_tests)
      
    # Extract p-values from the test results
      p_values <- sapply(shapiro_tests, function(x) x$p.value)
      
    # Highlight non-normally distributed groups (p-value < 0.05)
      non_normal_groups <- names(p_values[p_values < 0.05])
      cat("\nNon-normally distributed groups:", ifelse(length(non_normal_groups) > 0, paste(non_normal_groups, collapse = ", "), "None"), "\n")
      
    # Print the ggplot object
      print(p)
```


### Step 1: Simulate d18Ophosphate data for each eco_type based on distributions of emperical data.

```{r, results='hide', message=FALSE, warning=FALSE}
# Simulate dataset ------------------------------------------------------

  # Function to generate simulated dataset for a given eco_type
    simulate_eco_type <- function(subset_data, n_simulations = 1000) {
      mean_val <- mean(subset_data$d18O)
      sd_val <- sd(subset_data$d18O)
      
      simulated_values <- replicate(n_simulations, rnorm(1, mean_val, sd_val))
      return(simulated_values)
    }
    
  # Generate simulated datasets for each eco_type
    simulated_data <- grouped_data %>%
      summarise(simulated_d18O = list(simulate_eco_type(cur_data(), n_simulations = 1000))) %>%
      unnest(simulated_d18O)
    
  # Check the structure of the simulated_data
    str(simulated_data)
    
  # Plot histograms of the simulated data to compare against the empirical data
    ggplot(simulated_data, aes(x = simulated_d18O, fill = eco_type)) +
      geom_histogram(binwidth = 0.2, position = "identity", alpha = 0.7) +
      labs(title = "Simulated d18Op Data", x = "Simulated d18O", y = "Frequency") +
      scale_fill_manual(values = c("A" = "blue", "B" = "green")) +
      facet_wrap(~eco_type, scales = "free") +
      theme_minimal()
```

### Step 2: Generate random subsamples from simulated data.

```{r, results='hide', message=FALSE, warning=FALSE}
# Resampling simulated data--------------------------------------------------------------

     # Function to generate resamples for a given eco_type
    generate_resamples <- function(subset_data, sample_sizes = c(5, 10, 15, 20), n_resamples = 1000) {
      resampled_data <- lapply(sample_sizes, function(sample_size) {
        resamples <- replicate(n_resamples, sample(subset_data$d18O, size = sample_size, replace = TRUE))
        means <- colMeans(resamples)
        variances <- apply(resamples, 2, var)
        standard_errors <- apply(resamples, 2, function(x) sd(x) / sqrt(length(x)))
        standard_deviations <- apply(resamples, 2, sd)
        
        data.frame(
          sample_size = rep(sample_size, each = n_resamples),
          sim_d18Op_mean = means,
          sim_d18Op_var = variances,
          sim_d18Op_SE = standard_errors,
          sim_d18Op_SD = standard_deviations
        )
      })
      
      return(do.call(rbind, resampled_data))
    }

    
    # Generate resamples for each eco_type
    resampled_data <- grouped_data %>%
      group_modify(~ generate_resamples(.x, n_resamples = 1000))
    
    # Assuming resampled_data is the output from generate_resamples function
    resamples <- list()
    
    sample_sizes <- unique(resampled_data$sample_size)
    
    for (size in sample_sizes) {
      resamples[[paste0("sample_size_", size)]] <- subset(resampled_data, sample_size == size)
    }
    
    # Now, each subset is stored in resamples list
    # Access them using resamples$sample_size_5, subsetted_data$sample_size_10, etc.


```

### Step 3: Compute $\delta$^18^O~ambient_water~ 

Here we are calculating $\delta$^18^O~ambient_water~ from $\delta$^18^O~phosphate~ of the aquatic turtle *Glyptops sp.* and a aquatic/semi-aquatic crocodylomorph morphotype referred to as "Croc G". These equations are from Barrick et al. (1999) and Amiot et al. (2007), respectively.

Barrick et al. (1999) turtle equation for ambient water:

$\delta$^18^O~ambient_water~ = 1.01 ($\delta$^18^O~phosphate~) -23

Amiot et al. (2007) croc equation for ambient water:

$\delta$^18^O~ambient_water~ = 0.82 ($\delta$^18^O~phosphate~) -22.3

```{r, results='hide', message=FALSE, warning=FALSE}

  # Define d18Omw functions
    
    # d18Omw from croc d18Op (Amiot et al., 2007)
      crocwater <- function(mean_d18Op) {
        result <- 0.82 * mean_d18Op - 19.93
        return(data.frame(d18Omw = result))
      }
    
    # d18Omw from turtle d18Op (Barrick et al., 1999)
      turtlewater <- function(mean_d18Op) {
        result <- 1.01 * mean_d18Op - 22.3
        return(data.frame(d18Omw = result))
      }
  
  # Subset sim data by eco_type
    
    # Croc G
      # Subset resamples and extract Croc G rows
        croc_subsets <- lapply(resamples, function(df) subset(df, eco_type == "Croc G"))
      # Combine the Croc G subsets into a single data frame
        sim_croc <- do.call(rbind, croc_subsets)
      # Add d18Omw column to sim_croc
        sim_croc$d18Omw <- NA
      
    # Aquatic Turtle
      # Subset resamples and extract Aquatic Turtle rows
        turtle_subsets <- lapply(resamples, function(df) subset(df, eco_type == "Aquatic Turtle"))
      # Combine the Aquatic Turtle subsets into a single data frame
        sim_turtle <- do.call(rbind, turtle_subsets)
      # Add d18Omw column to sim_turtle
        sim_turtle$d18Omw <- NA

  # Compute d18O water values
    # Compute d18Omw from turtle d18Op
      sim_turtle$d18Omw <- turtlewater(sim_turtle$sim_d18Op_mean)$d18Omw
    # Compute d18Omw from croc d18Op
      sim_croc$d18Omw <- crocwater(sim_croc$sim_d18Op_mean)$d18Omw
      
      
      
  # Plot histograms to look at d18Omw distributions 
      
    # Combine sim_croc and sim_turtle into a single data frame for easier plotting
      combined_data <- rbind(cbind(sim_croc, species = "Croc"), cbind(sim_turtle, species = "Turtle"))
      
    # Plot histograms for each combination of eco_type and sample_size
      plot_panel <- ggplot(combined_data, aes(x = d18Omw, fill = species)) +
        geom_histogram(binwidth = 0.25, position = "dodge", alpha = 0.7) +
        facet_grid(eco_type ~ sample_size, scales = "free") +
        labs(title = "Histograms of d18Ow for Simulated Croc and Turtle Data",
             x = "d18Omw", y = "Frequency") +
        theme_minimal()
      
    # Display the plot
      print(plot_panel)
```


### Step 4: Compute dual-taxon temperature estimates

##### This is bricking my computer. I have not yet been able to successfully compute a temperature distribution. See "Dual-taxon Temperature Estimates" in "V1075_MonteCarloBootstrap.R"

##### Note about which taxon to use as proxy for $\delta$^18^O~ambient_water~
A t-test shows that the croc and turtle $\delta$^18^O~ambient_water~ distributions do not differ in this case. This suggests that 

```{r}

  # Setup
      
    # Subset resamples and extract Fish rows
      fish_subsets <- lapply(resamples, function(df) subset(df, eco_type == "Fish"))
      # Combine the Fish subsets into a single data frame
      sim_fish <- do.call(rbind, fish_subsets)
      
      str(sim_fish)
    
    # Create fishtemp function (Puceat et al., 2010)
      fishtemp <- function(fish_d18Op, NIST120c_mean, d18Omw) {
      temp <- 118.7 - 4.22 * ((fish_d18Op + (22.6 - NIST120c_mean)) - d18Omw)
      return(temp)
      }
      
  # Compute temps
      # Get distinct sample sizes
      distinct_sample_sizes <- unique(sim_turtle$sample_size)
      
      # Function to calculate temperature
      fishtemp <- function(fish_d18Op, NIST120c_mean, d18Omw) {
        temp <- 118.7 - 4.22 * ((fish_d18Op + (22.6 - NIST120c_mean)) - d18Omw)
        return(temp)
      }
      
      # Create an empty data frame to store results
      result_df <- data.frame(Sample_Size = numeric(),
                              Temperature = numeric())
     
      # This is where the loop will go which will compute the temps. It is commented out here because the run time is enormous. I'm working on that.
      
      # Iterate over distinct sample sizes
      #for (sample_size in distinct_sample_sizes) {
        # Subset sim_fish and sim_turtle for the current sample_size
        #subset_sim_fish <- subset(sim_fish, sample_size == sample_size)
        #subset_sim_turtle <- subset(sim_turtle, sample_size == sample_size)
        
        # Iterate over each combination of sim_fish$sim_d18Op_mean and sim_turtle$d18Omw
        #for (fish_d18Op_mean in subset_sim_fish$sim_d18Op_mean) {
          #for (turtle_d18Omw in subset_sim_turtle$d18Omw) {
            # Call fishtemp for the current combination
           # temperature <- fishtemp(fish_d18Op_mean, 22.6, turtle_d18Omw)
            
            # Store the result in the data frame
            #result_df <- rbind(result_df, data.frame(Sample_Size = sample_size, Temperature = temperature))
         # }
       # }
     # }
      
  # Plot temp distributions
      #ggplot(result_df, aes(x = Temperature, fill = as.factor(Sample_Size))) +
        #geom_histogram(position = "identity", alpha = 0.7, bins = 20) +
        #facet_wrap(~Sample_Size, scales = "free") +
        #labs(title = "Histogram of Temperature for Each Sample Size", x = "Temperature", y = "Frequency") +
        #theme_minimal()
```

### Step 5: Construct confidence intervals

```{r}

# Assuming "data" is your distribution
# Replace "data" with your actual data

# Calculate mean and standard deviation
  # mean_value <- mean(data)
  # sd_value <- sd(data)

# Calculate 95% confidence limits
  # lower_limit <- mean_value + qnorm(0.025) * sd_value
  # upper_limit <- mean_value + qnorm(0.975) * sd_value

# Print the confidence limits
  # cat("95% Confidence Interval: (", lower_limit, ", ", upper_limit, ")\n")


```

