---
title: "V1075 Monte Carlo"
author: "Matthew Allen"
date: "December 2023"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Step 1: Load packages and data

## !!! I want to source the data directly from GitHub, but Rmarkdown is giving me trouble !!!

```{r, results='hide', message=FALSE, warning=FALSE}
# Load required packages
library(dplyr)
library(purrr)
library(ggplot2)
library(RCurl)

# !!! V1075_MCdata is sourced from script "V1075_d18O_wrangle.R"

# local, if needed
  setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
  V1075_MCdata <- read.csv("V1075MC_data.csv")
  NIST120c <- read.csv("V1075_NIST120c.csv")

# Set number of Monte Carlo repetitions 
nMCrepetitions <- 1e3

# Subset V1075_cl by biological group
gar <- subset(V1075_MCdata, Taxon == "Lepisosteids")
shark <- subset(V1075_MCdata, Taxon == "Hybodonts")
glyptops <- subset(V1075_MCdata, Taxon == "Glyptops sp.")
naomichelys <- subset(V1075_MCdata, Taxon == "Naomichelys sp.")
crocG <- subset(V1075_MCdata, Taxon == "Neosuchian G")
crocA <- subset(V1075_MCdata, Taxon == "Neosuchian A")
crocB <- subset(V1075_MCdata, Taxon == "Neosuchian B")

# Bootstrapping
# Resample d18Op for each taxon
# Take mean of each resample
# Compile means in data frame

synth_shark <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(shark$d18O, replace = TRUE))) 

synth_gar <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(gar$d18O, replace = TRUE))) 
mean(synth_gar$means)

synth_glyptops <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(glyptops$d18O, replace = TRUE))) 

synth_naomichelys <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(naomichelys$d18O, replace = TRUE))) 

synth_crocG <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(crocG$d18O, replace = TRUE))) 

synth_crocA <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(crocA$d18O, replace = TRUE))) 

synth_crocB <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(crocB$d18O, replace = TRUE))) 

synth_NIST <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(NIST120c$d.18O.16O, replace = TRUE))) 

# Combine data frames into one
combined_data <- rbind(
  data.frame(group = "Gar", values = synth_gar$means),
  data.frame(group = "Sharks", values = synth_shark$means),
  data.frame(group = "Glyptops", values = synth_glyptops$means),
  data.frame(group = "Naomichelys", values = synth_naomichelys$means),
  data.frame(group = "Neosuchian G", values = synth_crocG$means),
  data.frame(group = "Neosuchian A", values = synth_crocA$means),
  data.frame(group = "Neosuchian B", values = synth_crocB$means),
  data.frame(group = "NIST", values = synth_NIST$means)
)

# Set order of facets
combined_data$group <- factor(combined_data$group, levels = c("Gar", "Sharks", "Glyptops", "Neosuchian G", "Neosuchian A", "Neosuchian B", "Naomichelys", "NIST"))

# Plot histogram of resampled means for each taxon
ggplot(combined_data, aes(x = values, fill = group)) +
  geom_histogram(position = "identity", alpha = 0.7, bins = 30, color = "black") +
  labs(title = "Histogram of Means",
       x = "Means",
       y = "Frequency") +
  theme_minimal() +
  facet_wrap(~group, scales = "free")


# Load the regression models

# Load Barrick regression model (from ~/Documents/GitHub/1075_Vertebrate_d18Op/Code/d18Ow_Proxy_Regressions.R)
Barrick_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/Barrick_reg_lm.rds")

# Load Amiot regression model (from ~/Documents/GitHub/1075_Vertebrate_d18Op/Code/d18Ow_Proxy_Regressions.R)
Amiot_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/Amiot_reg_lm.rds")

# Load Puceat, Longinelli, Nuti (PLN) regression model (from ~/Documents/GitHub/1075_Vertebrate_d18Op/Code/d18Ow_Proxy_Regressions.R)
PLN_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/PLNd18Op_reg_lm.rds")

# Load Tw~Ta transform model (from )
TwTa_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/TwTa_reg_lm.rds")


summary(Barrick_lm_model)
summary(Amiot_lm_model)
summary(PLN_lm_model)


```
# Croc Water
```{r}
# Croc Water --------------------------------------------------------------

# Extract the regression coefficients and standard errors
Amiot_model_summary <- summary(Amiot_lm_model)
Amiot_intercept <- coef(Amiot_lm_model)[1]
Amiot_slope <- coef(Amiot_lm_model)[2]
Amiot_intercept_se <- coef(Amiot_model_summary)[1, "Std. Error"]  # Standard error for intercept
Amiot_slope_se <- coef(Amiot_model_summary)[2, "Std. Error"]      # Standard error for slope

cat("Standard Error for Intercept:", Amiot_intercept_se, "\n")
cat("Standard Error for Slope:", Amiot_slope_se, "\n")

# Simulate regression coefficients for the regression model
set.seed(123)  # For reproducibility
n_iterations <- 1e3  # Number of Monte Carlo simulations

# Define 
Amiot_residual_sd <- summary(Amiot_lm_model)$sigma

# Generate simulated slope and intercept values
Amiot_simulated_slope <- rnorm(n_iterations, mean = Amiot_slope, sd = Amiot_slope_se)
Amiot_simulated_intercept <- rnorm(n_iterations, mean = Amiot_intercept, sd = Amiot_intercept_se)

# Monte Carlo simulation for the regression
# simulate residual error
Amiot_residual_error <- rnorm(n_iterations, mean = 0, sd = Amiot_residual_sd)

# Store Croc G d18Op synth means in vector
crocG_synthmeans_d18Op <- synth_crocG$means
mean(crocG_synthmeans_d18Op)

# Expand d18Op values to interact with all simulated parameters
expanded_d18Op <- rep(crocG_synthmeans_d18Op, each = n_iterations)
expanded_slopes <- rep(Amiot_simulated_slope, times = length(crocG_synthmeans_d18Op))
expanded_intercepts <- rep(Amiot_simulated_intercept, times = length(crocG_synthmeans_d18Op))
expanded_residuals <- rep(Amiot_residual_error, times = length(crocG_synthmeans_d18Op))

# Calculate water simulations
crocG_water_simulations <- expanded_slopes * expanded_d18Op + expanded_intercepts + expanded_residuals
mean(crocG_water_simulations)

# Sort the simulated water values
sorted_crocG_synthd18Owater <- sort(crocG_water_simulations)

# Calculate 95% CI percentiles
crocwatersynth_lower_95_CI <- quantile(sorted_crocG_synthd18Owater, probs = 0.025)
crocwatersynth_upper_95_CI <- quantile(sorted_crocG_synthd18Owater, probs = 0.975)

# Compute the mean of the data
mean_crocwater_synth <- mean(sorted_crocG_synthd18Owater)

# Print the results
cat("Mean crocG d18Owater:", round(mean_crocwater_synth, 2), "\n")
cat("95% CI for crocG d18Owater: [", round(crocwatersynth_lower_95_CI, 2), ",", round(crocwatersynth_upper_95_CI, 2), "]\n")


```

# Turtle Water 

``` {r}

# Extract the regression coefficients and standard errors
Barrick_model_summary <- summary(Barrick_lm_model)
Barrick_intercept <- coef(Barrick_lm_model)[1]
Barrick_slope <- coef(Barrick_lm_model)[2]
Barrick_intercept_se <- coef(Barrick_model_summary)[1, "Std. Error"]  # Standard error for intercept
Barrick_slope_se <- coef(Barrick_model_summary)[2, "Std. Error"]      # Standard error for slope

cat("Standard Error for Intercept:", Barrick_intercept_se, "\n")
cat("Standard Error for Slope:", Barrick_slope_se, "\n")

# Simulate regression coefficients for the Barrick regression model
set.seed(123)  # For reproducibility
n_iterations <- 1e3  # Number of Monte Carlo simulations

# Define 
Barrick_residual_sd <- summary(Barrick_lm_model)$sigma

# Generate simulated slope and intercept values
Barrick_simulated_slope <- rnorm(n_iterations, mean = Barrick_slope, sd = Barrick_slope_se)
Barrick_simulated_intercept <- rnorm(n_iterations, mean = Barrick_intercept, sd = Barrick_intercept_se)

# Monte Carlo simulation for the regression
# simulate residual error
Barrick_residual_error <- rnorm(n_iterations, mean = 0, sd = Barrick_residual_sd)

# Store Glyptops d18Op synth means in vector
glyp_synthmeans_d18Op <- synth_glyptops$means
mean(glyp_synthmeans_d18Op)

# Expand d18Op values to interact with all simulated parameters
glyp_expanded_d18Op <- rep(glyp_synthmeans_d18Op, each = n_iterations)
glyp_expanded_slopes <- rep(Barrick_simulated_slope, times = length(glyp_synthmeans_d18Op))
glyp_expanded_intercepts <- rep(Barrick_simulated_intercept, times = length(glyp_synthmeans_d18Op))
glyp_expanded_residuals <- rep(Barrick_residual_error, times = length(glyp_synthmeans_d18Op))

# Calculate water simulations
glyp_water_simulations <- glyp_expanded_slopes * glyp_expanded_d18Op + glyp_expanded_intercepts + glyp_expanded_residuals
mean(glyp_water_simulations)

# Sort the simulated water values
glyp_sorted_synthwater <- sort(glyp_water_simulations)

# Calculate 95% CI percentiles
glypwatersynth_lower_95_CI <- quantile(glyp_sorted_synthwater, probs = 0.025)
glypwatersynth_upper_95_CI <- quantile(glyp_sorted_synthwater, probs = 0.975)

# Compute the mean of the middle 95% of the data
mean_glyp_synthwater <- mean(glyp_sorted_synthwater)

# Print the results
cat("Mean Glyptops d18Owater:", round(mean_glyp_synthwater, 2), "\n")
cat("95% CI for Glyptops d18Owater: [", round(glypwatersynth_lower_95_CI, 2), ",", round(glypwatersynth_upper_95_CI, 2), "]\n")


```

# Combine Turtle and Croc Water Estimates

```{r}

# Define bootstrap iterations
n_iterations <- 1e3

# Random sampling and averaging
bootstrapped_d18Ow <- replicate(n_iterations, {
  sample_glyp <- sample(glyp_water_simulations, size = 1, replace = TRUE)
  sample_crocG <- sample(crocG_water_simulations, size = 1, replace = TRUE)
  mean(c(sample_glyp, sample_crocG))  # Average of the two
})

# Analyze combined distribution
mean_d18Ow <- mean(bootstrapped_d18Ow)
sd_d18Ow <- sd(bootstrapped_d18Ow)
quantiles <- quantile(bootstrapped_d18Ow, probs = c(0.025, 0.975))

# Print results
cat("Mean δ¹⁸Ow:", mean_d18Ow, "\n")
cat("95% CI for δ¹⁸Ow: [", quantiles[1], ",", quantiles[2], "]\n")

```

# Multi-Taxon Temperature
```{r}
# Extract the regression coefficients and standard errors
PLN_model_summary <- summary(PLN_lm_model)
PLN_intercept <- coef(PLN_lm_model)[1]
PLN_slope <- coef(PLN_lm_model)[2]
PLN_intercept_se <- coef(PLN_model_summary)[1, "Std. Error"]  # Standard error for intercept
PLN_slope_se <- coef(PLN_model_summary)[2, "Std. Error"]      # Standard error for slope

# Set up the number of Monte Carlo iterations
set.seed(123)
n_iterations <- 1e3

# Define input distributions
delta_Op_distribution <- synth_gar$means
delta_Ow_distribution <- bootstrapped_d18Ow
delta_ONBS120c_distribution <- synth_NIST$means

# Sanity checks (CAN REMOVE LATER)
mean(delta_Op_distribution)
mean(delta_Ow_distribution)
mean(delta_ONBS120c_distribution)

# Define regression parameters and their uncertainties
intercept <- PLN_intercept
intercept_sd <- PLN_intercept_se
slope <- PLN_slope
slope_sd <- PLN_slope_se

# Simulate regression coefficients
PLN_intercept_simulated <- rnorm(n_iterations, mean = intercept, sd = intercept_sd)
PLN_slope_simulated <- rnorm(n_iterations, mean = slope, sd = slope_sd)

# Extract residual standard error from temperature regression model
residual_sd <- summary(PLN_lm_model)$sigma  

# Initialize vector to store results
temperature_simulations <- numeric(n_iterations)

# Perform Monte Carlo simulations
for (i in 1:n_iterations) {
  # Sample one value from each input distribution
  delta_Op <- sample(delta_Op_distribution, 1, replace = TRUE)
  delta_Ow <- sample(delta_Ow_distribution, 1, replace = TRUE)
  delta_ONBS120c <- sample(delta_ONBS120c_distribution, 1, replace = TRUE)
  
  # Simulate regression parameters and residual error
  intercept_sim <- rnorm(1, mean = PLN_intercept, sd = PLN_intercept_se)
  slope_sim <- rnorm(1, mean = PLN_slope, sd = PLN_slope_se)
  residual_error <- rnorm(1, mean = 0, sd = residual_sd)
  
  # Calculate temperature for this iteration
  temperature_simulations[i] <- intercept_sim + slope_sim * (
    delta_Op + (22.6 - delta_ONBS120c) - delta_Ow
  ) + residual_error
}

# Summarize the results
mean_temperature <- mean(temperature_simulations)
lower_95_CI <- quantile(temperature_simulations, probs = 0.025)
upper_95_CI <- quantile(temperature_simulations, probs = 0.975)

# Display results
cat("Mean MAWSWT (°C):", mean_temperature, "\n")
cat("95% Confidence Interval (°C): [", lower_95_CI, ",", upper_95_CI, "]\n")

# Summary of temperature simulations
summary(temperature_simulations)

# Standard deviation
sd_temp_sim <- sd(temperature_simulations)

# Sample size
n <- length(temperature_simulations)

# Standard error of the mean
se_mean_temp_sim <- sd_temp_sim / sqrt(n)
cat("Standard Error of the Mean:", se_mean_temp_sim, "\n")

# Calculate statistics
mean_temp <- mean(temperature_simulations)
ci_lower <- quantile(temperature_simulations, probs = 0.025)
ci_upper <- quantile(temperature_simulations, probs = 0.975)

# Create the histogram using ggplot2
library(ggplot2)

ggplot(data.frame(temperature_simulations), aes(x = temperature_simulations)) +
  geom_histogram(bins = 50, fill = "blue", color = "black", alpha = 0.7) +
  # Add vertical lines for mean and 95% CI
  geom_vline(xintercept = mean_temp, color = "red", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = ci_lower, color = "blue", linetype = "dotted", linewidth = 1) +
  geom_vline(xintercept = ci_upper, color = "blue", linetype = "dotted", linewidth = 1) +
  # Add labels for the lines
  annotate("text", x = mean_temp, y = 50, label = paste("Mean:", round(mean_temp, 2)), 
           color = "red", angle = 90, vjust = -0.5) +
  annotate("text", x = ci_lower, y = 50, label = paste("Lower 95% CI:", round(ci_lower, 2)), 
           color = "blue", angle = 90, vjust = -0.5) +
  annotate("text", x = ci_upper, y = 50, label = paste("Upper 95% CI:", round(ci_upper, 2)), 
           color = "blue", angle = 90, vjust = -0.5) +
   # Customize y-axis to have ticks every 5
  scale_y_continuous(breaks = seq(0, 50, by = 5)) +
  # Add titles and labels
  labs(title = "Simulated Water Temperatures",
       x = "Tw_AMJJAS (°C)",
       y = "Frequency") +
  theme_minimal()
```

# Water-Air Correction

```{r}

# Load necessary libraries
library(ggplot2)
set.seed(123) # For reproducibility

# Regression coefficients from Tw~Ta model
# Extract the regression coefficients and standard errors
TwTa_model_summary <- summary(TwTa_lm_model)
TwTa_intercept <- coef(TwTa_lm_model)[1]
TwTa_slope <- coef(TwTa_lm_model)[2]
TwTa_intercept_se <- coef(TwTa_model_summary)[1, "Std. Error"]  # Standard error for intercept
TwTa_slope_se <- coef(TwTa_model_summary)[2, "Std. Error"]      # Standard error for slope

# Extract residual error
TwTa_residual_sd <- summary(TwTa_lm_model)$sigma

cat("Standard Error for Intercept:", TwTa_intercept_se, "\n")
cat("Standard Error for Slope:", TwTa_slope_se, "\n")

# Monte Carlo simulation parameters
n_iterations <- 1e3 # Number of Monte Carlo iterations

# Provide distribution of Tw_AMJJAS values
Tw_distribution <- temperature_simulations

# Monte Carlo simulation incorporating all uncertainties
Ta_simulations <- sapply(Tw_distribution, function(Tw) {
  TwTa_simulated_intercept <- rnorm(n_iterations, mean = TwTa_intercept, sd = TwTa_intercept_se)
  TwTa_simulated_slope <- rnorm(n_iterations, mean = TwTa_slope, sd = TwTa_slope_se)
  TwTa_residual_error <- rnorm(n_iterations, mean = 0, sd = TwTa_residual_sd)
  Tw * TwTa_simulated_slope + TwTa_simulated_intercept + TwTa_residual_error
})

# Compute mean and 95% CI for all simulations
mean_Ta <- apply(Ta_simulations, 1, mean)
lower_95_CI <- apply(Ta_simulations, 1, quantile, probs = 0.025)
upper_95_CI <- apply(Ta_simulations, 1, quantile, probs = 0.975)

# Overall mean and 95% CI
overall_mean_Ta <- mean(mean_Ta)
overall_lower_95_CI <- quantile(unlist(Ta_simulations), probs = 0.025)
overall_upper_95_CI <- quantile(unlist(Ta_simulations), probs = 0.975)

# Display results
cat("Mean MAWSAT (°C):", overall_mean_Ta, "\n")
cat("95% Confidence Interval (°C): [", overall_lower_95_CI, ",", overall_upper_95_CI, "]\n")

```

