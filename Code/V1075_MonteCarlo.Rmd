---
title: "V1075 Monte Carlo"
author: "Matthew Allen"
date: "December 2023"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Step 1: Load packages and data

## !!! I want to source the data directly from GitHub, but Rmarkdown is giving me trouble !!!

```{r, results='hide', message=FALSE, warning=FALSE}
# Load required packages
library(dplyr)
library(purrr)
library(ggplot2)
library(RCurl)

# !!! V1075_MCdata is sourced from script "V1075_d18O_wrangle.R"

# local, if needed
  setwd("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data")
  V1075_MCdata <- read.csv("V1075MC_data.csv")
  NIST120c <- read.csv("V1075_NIST120c.csv")

# Set number of Monte Carlo repetitions 
nMCrepetitions <- 1e5

# Subset V1075_cl by biological group
gar <- subset(V1075_MCdata, Taxon == "Lepisosteids")
shark <- subset(V1075_MCdata, Taxon == "Hybodonts")
glyptops <- subset(V1075_MCdata, Taxon == "Glyptops sp.")
naomichelys <- subset(V1075_MCdata, Taxon == "Naomichelys sp.")
crocG <- subset(V1075_MCdata, Taxon == "Neosuchian G")
crocA <- subset(V1075_MCdata, Taxon == "Neosuchian A")
crocB <- subset(V1075_MCdata, Taxon == "Neosuchian B")


# Bootstrapping
# Resample d18Op for each taxon
# Take mean of each resample
# Compile means in data frame

synth_shark <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(shark$d18O, replace = TRUE))) 

synth_gar <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(gar$d18O, replace = TRUE))) 
mean(synth_gar$means)

synth_glyptops <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(glyptops$d18O, replace = TRUE))) 

synth_naomichelys <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(naomichelys$d18O, replace = TRUE))) 

synth_crocG <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(crocG$d18O, replace = TRUE))) 

synth_crocA <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(crocA$d18O, replace = TRUE))) 

synth_crocB <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(crocB$d18O, replace = TRUE))) 

synth_NIST <- data_frame(num = 1:nMCrepetitions) %>% 
  group_by(num) %>% 
  mutate(means = mean(sample(NIST120c$d.18O.16O, replace = TRUE))) 




# Combine data frames into one
combined_data <- rbind(
  data.frame(group = "Gar", values = synth_gar$means),
  data.frame(group = "Sharks", values = synth_shark$means),
  data.frame(group = "Glyptops", values = synth_glyptops$means),
  data.frame(group = "Naomichelys", values = synth_naomichelys$means),
  data.frame(group = "Neosuchian G", values = synth_crocG$means),
  data.frame(group = "Neosuchian A", values = synth_crocA$means),
  data.frame(group = "Neosuchian B", values = synth_crocB$means),
  data.frame(group = "NIST", values = synth_NIST$means)
)

# Set order of facets
combined_data$group <- factor(combined_data$group, levels = c("Gar", "Sharks", "Glyptops", "Neosuchian G", "Neosuchian A", "Neosuchian B", "Naomichelys", "NIST"))

# Plot histogram of resampled means for each taxon
ggplot(combined_data, aes(x = values, fill = group)) +
  geom_histogram(position = "identity", alpha = 0.7, bins = 30, color = "black") +
  labs(title = "Histogram of Means",
       x = "Means",
       y = "Frequency") +
  theme_minimal() +
  facet_wrap(~group, scales = "free")


# Load the regression models

# Load Barrick regression model (from ~/Documents/GitHub/1075_Vertebrate_d18Op/Code/d18Ow_Proxy_Regressions.R)
Barrick_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/Barrick_reg_lm.rds")

# Load Amiot regression model (from ~/Documents/GitHub/1075_Vertebrate_d18Op/Code/d18Ow_Proxy_Regressions.R)
Amiot_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/Amiot_reg_lm.rds")

# Load Puceat, Longinelli, Nuti (PLN) regression model (from ~/Documents/GitHub/1075_Vertebrate_d18Op/Code/d18Ow_Proxy_Regressions.R)
PLN_lm_model <- readRDS("/Users/allen/Documents/GitHub/1075_Vertebrate_d18Op/Data/PLNd18Op_reg_lm.rds")

summary(Barrick_lm_model)
summary(Amiot_lm_model)
summary(PLN_lm_model)


```
# Croc Water
```{r}
# Croc Water --------------------------------------------------------------

# Extract the regression coefficients and standard errors
Amiot_model_summary <- summary(Amiot_lm_model)
Amiot_intercept <- coef(Amiot_lm_model)[1]
Amiot_slope <- coef(Amiot_lm_model)[2]
Amiot_intercept_se <- coef(Amiot_model_summary)[1, "Std. Error"]  # Standard error for intercept
Amiot_slope_se <- coef(Amiot_model_summary)[2, "Std. Error"]      # Standard error for slope

cat("Standard Error for Intercept:", Amiot_intercept_se, "\n")
cat("Standard Error for Slope:", Amiot_slope_se, "\n")

# Define function to compute d18Owater with regression uncertainty
crocwater <- function(crocG_synthmeans, slope, intercept) {
  slope * crocG_synthmeans + intercept
}

# Simulate regression coefficients for the regression model
set.seed(123)  # For reproducibility
n_iterations <- 1e5  # Number of Monte Carlo simulations

# Define 
Amiot_residual_sd <- summary(Amiot_lm_model)$sigma

# Generate simulated slope and intercept values
Amiot_simulated_slope <- rnorm(n_iterations, mean = Amiot_slope, sd = Amiot_slope_se)
Amiot_simulated_intercept <- rnorm(n_iterations, mean = Amiot_intercept, sd = Amiot_intercept_se)

# Monte Carlo simulation for the regression
# simulate residual error
Amiot_residual_error <- rnorm(n_iterations, mean = 0, sd = Amiot_residual_sd)

# Store Croc G d18Op synth means in vector
crocG_synthmeans_d18Op <- synth_crocG$means
mean(crocG_synthmeans_d18Op)

# simulate d18Owater estimates
crocG_water_simulations <- Amiot_simulated_slope * crocG_synthmeans_d18Op + Amiot_simulated_intercept + Amiot_residual_error
mean(crocG_water_simulations)

# Sort the simulated water values
sorted_crocG_synthd18Owater <- sort(crocG_water_simulations)

# Calculate 95% CI percentiles
crocwatersynth_lower_95_CI <- quantile(sorted_crocG_synthd18Owater, probs = 0.025)
crocwatersynth_upper_95_CI <- quantile(sorted_crocG_synthd18Owater, probs = 0.975)

# Compute the mean of the data
mean_crocwater_synth <- mean(sorted_crocG_synthd18Owater)

# Print the results
cat("Mean crocG d18Owater:", round(mean_crocwater_synth, 2), "\n")
cat("95% CI for crocG d18Owater: [", round(crocwatersynth_lower_95_CI, 2), ",", round(crocwatersynth_upper_95_CI, 2), "]\n")

library(knitr)
results <- data.frame(
  Statistic = c("Mean", "Lower 95% CI", "Upper 95% CI"),
  Value = c(round(mean_crocwater_synth, 2), round(crocwatersynth_lower_95_CI, 2), round(crocwatersynth_upper_95_CI, 2))
)
kable(results, caption = "CrocG d18Owater Estimates")

```

# Turtle Water 

``` {r}

# Extract the regression coefficients and standard errors
Barrick_model_summary <- summary(Barrick_lm_model)
Barrick_intercept <- coef(Barrick_lm_model)[1]
Barrick_slope <- coef(Barrick_lm_model)[2]
Barrick_intercept_se <- coef(Barrick_model_summary)[1, "Std. Error"]  # Standard error for intercept
Barrick_slope_se <- coef(Barrick_model_summary)[2, "Std. Error"]      # Standard error for slope

cat("Standard Error for Intercept:", Barrick_intercept_se, "\n")
cat("Standard Error for Slope:", Barrick_slope_se, "\n")

# Store Glyptops d18Op synth means in vector
glyp_synthmeans_d18Op <- synth_glyptops$means

# Define function to compute d18Owater with regression uncertainty
turtlewater <- function(glyp_synthmeans_d18Op, Barrick_slope, Barrick_intercept) {
  Barrick_slope * glyp_synthmeans_d18Op + Barrick_intercept
}

# Simulate regression coefficients for the Barrick regression model
set.seed(123)  # For reproducibility
n_iterations <- 1e5  # Number of Monte Carlo simulations

# Define 
Barrick_residual_sd <- summary(Barrick_lm_model)$sigma

# Generate simulated slope and intercept values
Barrick_simulated_slope <- rnorm(n_iterations, mean = Barrick_slope, sd = Barrick_slope_se)
Barrick_simulated_intercept <- rnorm(n_iterations, mean = Barrick_intercept, sd = Barrick_intercept_se)

# Monte Carlo simulation for the regression
# simulate residual error
Barrick_residual_error <- rnorm(n_iterations, mean = 0, sd = Barrick_residual_sd)

# Store Glyptops d18Op synth means in vector
glyp_synthmeans_d18Op <- synth_glyptops$means
mean(glyp_synthmeans_d18Op)

# simulate d18Owater estimates
glyp_water_simulations <- Barrick_simulated_slope * glyp_synthmeans_d18Op + Barrick_simulated_intercept + Barrick_residual_error
mean(glyp_water_simulations)

# Sort the simulated water values
glyp_sorted_synthwater <- sort(glyp_water_simulations)

# Calculate 95% CI percentiles
glypwatersynth_lower_95_CI <- quantile(glyp_sorted_synthwater, probs = 0.025)
glypwatersynth_upper_95_CI <- quantile(glyp_sorted_synthwater, probs = 0.975)

# Compute the mean of the middle 95% of the data
mean_glyp_synthwater <- mean(glyp_sorted_synthwater)

# Print the results
cat("Mean Glyptops d18Owater:", round(mean_glyp_synthwater, 2), "\n")
cat("95% CI for Glyptops d18Owater: [", round(glypwatersynth_lower_95_CI, 2), ",", round(glypwatersynth_upper_95_CI, 2), "]\n")


```

# Combine Turtle and Croc Water Estimates

```{r}


# Define bootstrap iterations
n_iterations <- 1e5

# Random sampling and averaging
bootstrapped_d18Ow <- replicate(n_iterations, {
  sample_glyp <- sample(glyp_water_simulations, size = 1, replace = TRUE)
  sample_crocG <- sample(crocG_water_simulations, size = 1, replace = TRUE)
  mean(c(sample_glyp, sample_crocG))  # Average of the two
})

# Analyze combined distribution
mean_d18Ow <- mean(bootstrapped_d18Ow)
sd_d18Ow <- sd(bootstrapped_d18Ow)
quantiles <- quantile(bootstrapped_d18Ow, probs = c(0.025, 0.975))

# Print results
cat("Mean δ¹⁸Ow:", mean_d18Ow, "\n")
cat("95% CI for δ¹⁸Ow: [", quantiles[1], ",", quantiles[2], "]\n")

```

# Multi-Taxon Temperature
```{r}
# Extract the regression coefficients and standard errors
PLN_model_summary <- summary(PLN_lm_model)
PLN_intercept <- coef(PLN_lm_model)[1]
PLN_slope <- coef(PLN_lm_model)[2]
PLN_intercept_se <- coef(PLN_model_summary)[1, "Std. Error"]  # Standard error for intercept
PLN_slope_se <- coef(PLN_model_summary)[2, "Std. Error"]      # Standard error for slope

# Set up the number of Monte Carlo iterations
set.seed(123)
n_iterations <- 1e5

# Define input distributions (replace with your actual data)
delta_Op_distribution <- synth_gar$means
delta_Ow_distribution <- bootstrapped_d18Ow
delta_ONBS120c_distribution <- synth_NIST$means

# Sanity checks (CAN REMOVE LATER)
mean(delta_Op_distribution)
mean(delta_Ow_distribution)
mean(delta_ONBS120c_distribution)

# Define regression parameters and their uncertainties (1 sigma errors provided)
intercept <- PLN_intercept
intercept_sd <- PLN_intercept_se
slope <- PLN_slope
slope_sd <- PLN_slope_se

# Simulate regression coefficients using the 1 sigma uncertainties
PLN_intercept_simulated <- rnorm(n_iterations, mean = intercept, sd = intercept_sd)
PLN_slope_simulated <- rnorm(n_iterations, mean = slope, sd = slope_sd)

# Extract residual standard error from your regression model
residual_sd <- summary(PLN_lm_model)$sigma  # Replace `regression_model` with your lm model

# Monte Carlo simulation for the regression
temperature_simulations <- PLN_intercept_simulated + PLN_slope_simulated * (
  delta_Op_distribution + (22.6 - delta_ONBS120c_distribution) - delta_Ow_distribution
) + rnorm(n_iterations, mean = 0, sd = residual_sd)

# Summarize the results
mean_temperature <- mean(temperature_simulations)
lower_95_CI <- quantile(temperature_simulations, probs = 0.025)
upper_95_CI <- quantile(temperature_simulations, probs = 0.975)

# Display results
cat("Mean Temperature (°C):", mean_temperature, "\n")
cat("95% Confidence Interval (°C): [", lower_95_CI, ",", upper_95_CI, "]\n")

# Summary of temperature simulations
summary(temperature_simulations)

# Standard deviation
sd_temp_sim <- sd(temperature_simulations)

# Sample size
n <- length(temperature_simulations)

# Standard error of the mean
se_mean_temp_sim <- sd_temp_sim / sqrt(n)
cat("Standard Error of the Mean:", se_mean_temp_sim, "\n")

# Calculate statistics
mean_temp <- mean(temperature_simulations)
ci_lower <- quantile(temperature_simulations, probs = 0.025)
ci_upper <- quantile(temperature_simulations, probs = 0.975)

# Create the histogram using ggplot2
library(ggplot2)

ggplot(data.frame(temperature_simulations), aes(x = temperature_simulations)) +
  geom_histogram(bins = 50, fill = "blue", color = "black", alpha = 0.7) +
  # Add vertical lines for mean and 95% CI
  geom_vline(xintercept = mean_temp, color = "red", linetype = "dashed", size = 1) +
  geom_vline(xintercept = ci_lower, color = "blue", linetype = "dotted", size = 1) +
  geom_vline(xintercept = ci_upper, color = "blue", linetype = "dotted", size = 1) +
  # Add labels for the lines
  annotate("text", x = mean_temp, y = 4000, label = paste("Mean:", round(mean_temp, 2)), 
           color = "red", angle = 90, vjust = -0.5) +
  annotate("text", x = ci_lower, y = 4000, label = paste("Lower 95% CI:", round(ci_lower, 2)), 
           color = "blue", angle = 90, vjust = -0.5) +
  annotate("text", x = ci_upper, y = 4000, label = paste("Upper 95% CI:", round(ci_upper, 2)), 
           color = "blue", angle = 90, vjust = -0.5) +
   # Customize y-axis to have ticks every 5
  scale_y_continuous(breaks = seq(0, 7000, by = 5)) +
  # Add titles and labels
  labs(title = "Simulated Temperature Distribution",
       x = "Temperature (°C)",
       y = "Frequency") +
  theme_minimal()
```

# Water-Air Correction

```{r}


# Load necessary libraries
library(ggplot2)
set.seed(123) # For reproducibility

# Regression coefficients from your model
intercept <- 4.4788
slope <- 0.7668
intercept_se <- 3.5883
slope_se <- 0.1340
residual_sd <- 1.586 # Residual standard error from the model

# Monte Carlo simulation parameters
n_iterations <- 1e5 # Number of Monte Carlo iterations

# Provide your distribution of Tw_AMJJAS values
Tw_distribution <- temperature_simulations

# Vectorized Monte Carlo simulation
# Simulate regression coefficients
simulated_intercept <- rnorm(n_iterations, mean = intercept, sd = intercept_se)
simulated_slope <- rnorm(n_iterations, mean = slope, sd = slope_se)
residual_error <- rnorm(n_iterations, mean = 0, sd = residual_sd)

# Compute Ta for all iterations and Tw values in a single step
Ta_simulations <- Tw_distribution * simulated_slope + simulated_intercept + residual_error

# Compute statistics for each Tw value
mean_Ta <- mean(Ta_simulations)
lower_95_CI <- quantile(Ta_simulations, probs = 0.025)
upper_95_CI <- quantile(Ta_simulations, probs = 0.975)

# Display results
cat("Mean Temperature (°C):", mean_Ta, "\n")
cat("95% Confidence Interval (°C): [", lower_95_CI, ",", upper_95_CI, "]\n")


```

